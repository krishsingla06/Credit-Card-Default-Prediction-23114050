{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4021802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Read the dataset\n",
    "df = pd.read_csv('train_dataset_final1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bc1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214929da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#in age replace nulls with mean\n",
    "df['age'].fillna(df['age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5eee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "sns.countplot(x='next_month_default', data=df)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "print(df['next_month_default'].value_counts(normalize=True))\n",
    "\n",
    "# -> 20% of users are likely to default next month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a2004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['sex', 'education', 'marriage']\n",
    "\n",
    "#print total rows in the dataset\n",
    "print(\"Total rows in the dataset:\", len(df))\n",
    "\n",
    "for col in categorical_cols:\n",
    "    sns.countplot(x=col, data=df)\n",
    "    plt.title(f'{col} distribution')\n",
    "    plt.show()\n",
    "    print(f\"{col} unique values:\", df[col].unique())\n",
    "    print(df[col].value_counts(normalize=True) * 100)\n",
    "    print(df[col].value_counts())\n",
    "\n",
    "# 297 outliers for education\n",
    "# 273 outliers for marriage\n",
    "# Very less married people in the dataset -> only 53 out of 25247\n",
    "\n",
    "#In marriage replace 3+ with median of 0,1,2\n",
    "df['marriage'] = df['marriage'].replace(0, 3)\n",
    "\n",
    "#In edu replace 3+ with median of 0,1,2\n",
    "df['education'] = df['education'].replace(0, 4)\n",
    "df['education'] = df['education'].replace(5, 4)\n",
    "df['education'] = df['education'].replace(6, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for age\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.boxplot(y='age', data=df)\n",
    "plt.title('Boxplot of Age')\n",
    "plt.ylabel('Age')\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Number of outliers in age\n",
    "Q1 = df['age'].quantile(0.25)\n",
    "Q3 = df['age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = df[(df['age'] < (Q1 - 1.5 * IQR)) | (df['age'] > (Q3 + 1.5 * IQR))]\n",
    "print(f'Number of outliers in age: {len(outliers)}')\n",
    "\n",
    "\n",
    "# Capping the outliers to upper IQR bound\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "print(df.shape)\n",
    "df['age'] = df['age'].clip(lower=lower_bound, upper=upper_bound)\n",
    "print(df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KDE plot: Age distributions split by default status\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "sns.kdeplot(\n",
    "    data=df[df['next_month_default'] == 1],\n",
    "    x='age',\n",
    "    label='Default',\n",
    "    fill=True,\n",
    "    color=\"#ff7f0e\"\n",
    ")\n",
    "plt.title(\"KDE Plot: Age Distribution by Default Status\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aed988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA for Limit Balance\n",
    "# 2. Boxplot of Credit Limit\n",
    "plt.figure(figsize=(6, 1.5))\n",
    "sns.boxplot(x=df['LIMIT_BAL'])\n",
    "plt.title(\"Boxplot of Credit Limits\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#also print histogram\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(df['LIMIT_BAL'], bins=50, kde=True)\n",
    "plt.title(\"Histogram of Credit Limits\")\n",
    "plt.xlabel(\"Credit Limit\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of outliers in LIMIT_BAL\n",
    "\n",
    "Q1 = df['LIMIT_BAL'].quantile(0.25)\n",
    "Q3 = df['LIMIT_BAL'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Capping the outliers to upper IQR bound\n",
    "lower_bound = max(Q1 - 1.5 * IQR,0)\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df['LIMIT_BAL'] < lower_bound) | (df['LIMIT_BAL'] > upper_bound)]\n",
    "print(f'Lower bound: {lower_bound}, Upper bound: {upper_bound}')\n",
    "print(f'Number of outliers in LIMIT_BAL: {len(outliers)}')\n",
    "\n",
    "print(df.shape)\n",
    "df['LIMIT_BAL'] = df['LIMIT_BAL'].clip(lower=lower_bound, upper=upper_bound)\n",
    "# Print dimensions after cleaning\n",
    "print(\"Shape after capping LIMIT_BAL outliers:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kde plot for Limit Balance with default status\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.kdeplot(\n",
    "    data=df[df['next_month_default'] == 1],\n",
    "    x='LIMIT_BAL',\n",
    "    label='Default',\n",
    "    fill=True,\n",
    "    color=\"#ff7f0e\"\n",
    ")\n",
    "plt.title(\"KDE Plot: Credit Limit Distribution by Default Status\")\n",
    "plt.xlabel(\"Limit Balance\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_status_cols = ['pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']\n",
    "\n",
    "for col in pay_status_cols:\n",
    "    sns.countplot(x=col, data=df)\n",
    "    plt.title(f'{col} distribution')\n",
    "    plt.show()\n",
    "    print(f\"{col} unique values:\", df[col].unique())\n",
    "    print(f\"{col} value counts:\\n\", df[col].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Melt your pay‐status columns into long form\n",
    "# Use the correct column names as in your DataFrame\n",
    "pay_status_cols = ['pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']\n",
    "df_long = (\n",
    "    df\n",
    "    .reset_index()                         # preserve original index as “customer_id” if you like\n",
    "    .melt(id_vars=['next_month_default'], \n",
    "          value_vars=pay_status_cols,\n",
    "          var_name='month',\n",
    "          value_name='pay_status')\n",
    ")\n",
    "\n",
    "# Convert next_month_default to int for aggregation\n",
    "df_long['next_month_default'] = df_long['next_month_default'].astype(int)\n",
    "\n",
    "# 2) Compute default rate by (month, pay_status)\n",
    "pivot = (\n",
    "    df_long\n",
    "    .groupby(['month','pay_status'])['next_month_default']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .pivot(index='pay_status', columns='month', values='next_month_default')\n",
    ")\n",
    "\n",
    "# 3) Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=\"YlOrBr\", cbar_kws={'label':'Default Rate'})\n",
    "plt.title(\"Default Rate by PAY Status and Month\")\n",
    "plt.xlabel(\"Month (0 = most recent)\")\n",
    "plt.ylabel(\"PAY Status Code\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Shape after dropping outliers:\", df.shape)\n",
    "\n",
    "bill_cols = [f'Bill_amt{i}' for i in range(1, 7)]\n",
    "\n",
    "for col in bill_cols:\n",
    "#     sns.boxplot(x=df[col])\n",
    "#     plt.title(f'Boxplot of {col}')\n",
    "#     plt.show()\n",
    "# # Check for negative values in bill columns\n",
    "#     print(\"Negative values in bill columns:\")\n",
    "#     print(df[col].lt(0).sum())\n",
    "# If negative values exist, replace them with 0\n",
    "    df[col] = df[col].clip(lower=0)\n",
    "# Clip the bill amounts with IQR method\n",
    "# Capping the bill amounts to upper IQR bound\n",
    "#     Q1 = df[col].quantile(0.25)\n",
    "#     Q3 = df[col].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "# # print number of outliers in bill amounts\n",
    "#     outliers = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))]\n",
    "#     print(f'Number of outliers in {col}: {len(outliers)}')\n",
    "# #removedcapping\n",
    "#     # df[col] = df[col].clip(lower=Q1 - 1.5 * IQR, upper=Q3 + 1.5 * IQR)\n",
    "# Print dimensions after cleaning\n",
    "    print(\"Shape after capping bill amounts outliers:\", df.shape)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(df[col], binwidth=10000)\n",
    "    plt.title(f'Distribution of {col} after capping outliers')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "# Check for negative values in bill columns after clipping\n",
    "    # print(\"Negative values in bill columns after clipping:\")\n",
    "    # print(df[col].lt(0).sum())\n",
    "# KDE plot for Bill Amounts with default status\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.kdeplot(\n",
    "        data=df[df['next_month_default'] == 1],\n",
    "        x=col,\n",
    "        label='Default',\n",
    "        fill=True,\n",
    "        color=\"#ff7f0e\"\n",
    "    )\n",
    "    plt.title(f\"KDE Plot: {col} Distribution by Default Status\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#similarly for pay amounts\n",
    "pay_cols = [f'pay_amt{i}' for i in range(1, 7)]\n",
    "for col in pay_cols:\n",
    "    # print(\"\\n\" + \"=\"*40)\n",
    "    # print(col, \"summary stats:\")\n",
    "    # print(df[col].describe(), \"\\n\")\n",
    "    \n",
    "    # clip negatives\n",
    "    # negs = (df[col] < 0).sum()\n",
    "    # print(f\"{col} negative values: {negs}\")\n",
    "    df[col] = df[col].clip(lower=0)\n",
    "    \n",
    "    # IQR bounds\n",
    "    # Q1, Q3 = df[col].quantile([0.25, 0.75])\n",
    "    # IQR = Q3 - Q1\n",
    "    # low, high = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "    # lo_count = (df[col] < low).sum()\n",
    "    # hi_count = (df[col] > high).sum()\n",
    "    # print(f\"{col} outliers  < {low:.2f}: {lo_count},  > {high:.2f}: {hi_count}\")\n",
    "    # df[col] = df[col].clip(lower=low, upper=high)\n",
    "    \n",
    "    # histogram with smaller bins\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df[col], bins=50, kde=True)\n",
    "    plt.title(f\"{col} after clipping & IQR capping\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfc46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_cols = ['AVG_Bill_amt', 'PAY_TO_BILL_ratio']\n",
    "\n",
    "# for col in eng_cols:\n",
    "#     # lower = df[col].quantile(0.005)\n",
    "#     # upper = df[col].quantile(0.975)\n",
    "#     # df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "#     # df.reset_index(drop=True, inplace=True)\n",
    "#     # print(f\"After capping, {col} shape: {df[col].shape}\")\n",
    "#     # now plot\n",
    "#     sns.histplot(df[col], kde=True)\n",
    "#     plt.title(f'Distribution of {col} after capping')\n",
    "#     plt.show()\n",
    "\n",
    "# clip eng_cols to 0.005 and 0.975 quantiles\n",
    "# for col in eng_cols:\n",
    "#     lower = df[col].quantile(0.005)\n",
    "#     upper = df[col].quantile(0.975)\n",
    "#     df[col] = df[col].clip(lower=lower, upper=upper)\n",
    "#     print(f\"After capping, {col} shape: {df[col].shape}\")\n",
    "#     # now plot\n",
    "#     sns.histplot(df[col], kde=True)\n",
    "#     plt.title(f'Distribution of {col} after capping')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#make negative values in engineering columns to 0\n",
    "for col in eng_cols:\n",
    "    df[col] = df[col].clip(lower=0)\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution of {col} after clipping negative values')\n",
    "    plt.show()\n",
    "\n",
    "#apply log transformation to engineering columns\n",
    "# for col in eng_cols:\n",
    "#     if(col == 'PAY_TO_BILL_ratio'):\n",
    "#         continue\n",
    "#     df[col] = np.log1p(df[col])  # log1p handles zero values correctly\n",
    "#     sns.histplot(df[col], kde=True)\n",
    "#     plt.title(f'Distribution of {col} after log transformation')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Clip the engineering columns to 0.005 and 0.975 quantiles\n",
    "for col in eng_cols:\n",
    "    lower = df[col].quantile(0.05)\n",
    "    upper = df[col].quantile(0.95)\n",
    "    #df[col] = df[col].clip(lower=lower, upper=upper)\n",
    "    print(f\"After capping, {col} shape: {df[col].shape}\")\n",
    "    # now plot\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution of {col} after capping')\n",
    "    plt.show()\n",
    "    \n",
    "# see later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relation between engineering columns and default status\n",
    "# kde plot for AVG_Bill_amt (log transformed) with default status\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.kdeplot(\n",
    "    data=df[df['next_month_default'] == 1],\n",
    "    x='AVG_Bill_amt',\n",
    "    label='Default',\n",
    "    fill=True,\n",
    "    color=\"#ff7f0e\"\n",
    ")\n",
    "\n",
    "\n",
    "plt.title(\"KDE Plot: AVG_Bill_amt Distribution by Default Status\")\n",
    "plt.xlabel(\"AVG_Bill_amt\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# kde plot for PAY_TO_BILL_ratio with default status\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.kdeplot(\n",
    "    data=df[df['next_month_default'] == 1],\n",
    "    x='PAY_TO_BILL_ratio',\n",
    "    label='Default',\n",
    "    fill=True,\n",
    "    color=\"#ff7f0e\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"KDE Plot: PAY_TO_BILL_ratio Distribution by Default Status\")\n",
    "plt.xlabel(\"PAY_TO_BILL_ratio\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbfb457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA for Bill Amounts# Columns for monthly bill amounts\n",
    "bill_cols = ['Bill_amt6', 'Bill_amt5', 'Bill_amt4', 'Bill_amt3', 'Bill_amt2', 'Bill_amt1']  # reversed for chronological order\n",
    "\n",
    "# Group by default status\n",
    "bill_means = df.groupby('next_month_default')[bill_cols].mean().T\n",
    "bill_means.columns = ['Non-Defaulters', 'Defaulters'] if 0 in bill_means.columns else ['Defaulters', 'Non-Defaulters']\n",
    "\n",
    "# Plot\n",
    "bill_means.plot(figsize=(8, 4), marker='o')\n",
    "plt.title(\"Average Monthly Bill Amounts\\nDefaulters vs Non-Defaulters\")\n",
    "plt.xlabel(\"Month (6 = Oldest, 1 = Most Recent)\")\n",
    "plt.ylabel(\"Average Bill Amount\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payment columns (chronologically reversed)\n",
    "pay_cols_amt = ['pay_amt6', 'pay_amt5', 'pay_amt4', 'pay_amt3', 'pay_amt2', 'pay_amt1']\n",
    "\n",
    "# Group by default status and calculate average\n",
    "pay_means = df.groupby('next_month_default')[pay_cols_amt].mean().T\n",
    "pay_means.columns = ['Non-Defaulters', 'Defaulters'] if 0 in pay_means.columns else ['Defaulters', 'Non-Defaulters']\n",
    "\n",
    "# Plot\n",
    "pay_means.plot(figsize=(8, 4), marker='o')\n",
    "plt.title(\"Average Monthly Payment Amounts\\nDefaulters vs Non-Defaulters\")\n",
    "plt.xlabel(\"Month (6 = Oldest, 1 = Most Recent)\")\n",
    "plt.ylabel(\"Average Payment\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ef8471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define delay_bucket function\n",
    "def delay_bucket(x):\n",
    "    if x <= 1:\n",
    "        return 'On Time to 1 Month Delay'\n",
    "    elif 2 <= x <= 4:\n",
    "        return '2  Months Delay to 4 Months Delay'\n",
    "    else:\n",
    "        return '4 Months+ Delay'\n",
    "\n",
    "#for pay_0 to pay_6, create buckets and plot default rate\n",
    "for col in pay_status_cols[:]:\n",
    "    df[f'{col}_bucket'] = df[col].apply(delay_bucket)\n",
    "    grouped = df.groupby(f'{col}_bucket')['next_month_default'].agg(['mean', 'count']).reset_index()\n",
    "    grouped.columns = [f'{col}_bucket', 'default_rate', 'count']\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.barplot(x=f'{col}_bucket', y='default_rate', data=grouped, order=[\n",
    "        'On Time to 1 Month Delay', \n",
    "        '2  Months Delay to 4 Months Delay', \n",
    "        '4 Months+ Delay'\n",
    "    ])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f'Default Rate vs {col} Delay Bucket')\n",
    "    plt.ylabel('Default Rate')\n",
    "    plt.xlabel(f'{col} Bucket')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb906e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9cff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LIMIT_BAL buckets\n",
    "bins = [0, 50000, 100000, 150000, 200000, 250000, 300000, 350000, 400000, 450000, 5000000, np.inf]\n",
    "labels = ['0-50K', '50K-100K', '100K-150K', '150K-200K', '200K-250K', '250K-300K', '300K-350K', '350K-400K', '400K-450K', '450K-500K', '500K+']\n",
    "\n",
    "df['LIMIT_BAL_bucket'] = pd.cut(df['LIMIT_BAL'], bins=bins, labels=labels)\n",
    "\n",
    "# Compute default rate for each LIMIT_BAL bucket\n",
    "grouped_limit = df.groupby('LIMIT_BAL_bucket')['next_month_default'].agg(['mean', 'count']).reset_index()\n",
    "\n",
    "grouped_limit.columns = ['LIMIT_BAL_bucket', 'default_rate', 'count']\n",
    "# Plot default rate for LIMIT_BAL buckets\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='LIMIT_BAL_bucket', y='default_rate', data=grouped_limit)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Default Rate vs LIMIT_BAL Bucket')\n",
    "plt.ylabel('Default Rate')\n",
    "plt.xlabel('LIMIT_BAL Bucket')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#also plot a continuous plot for LIMIT_BAL something like a kde plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.kdeplot(\n",
    "    data=df[df['next_month_default'] == 1],\n",
    "    x='LIMIT_BAL',\n",
    "    label='No Default',\n",
    "    fill=True,\n",
    "    color=\"#ff7f0e\"\n",
    ")\n",
    "\n",
    "plt.title(\"KDE Plot: Credit Limit Distribution by Default Status\")\n",
    "plt.xlabel(\"Limit Balance\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcdf6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['education', 'sex', 'marriage']\n",
    "\n",
    "for var in categorical_vars:\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.barplot(x=var, y='next_month_default', data=df)\n",
    "    plt.title(f'Default Rate by {var.capitalize()}')\n",
    "    plt.ylabel('Default Rate')\n",
    "    plt.xlabel(var.capitalize())\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(columns=['Customer_ID'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = df['sex'].astype('category')\n",
    "df['education'] = df['education'].astype('category')\n",
    "df['marriage'] = df['marriage'].astype('category')\n",
    "df['next_month_default'] = df['next_month_default'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e31511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop 'pay_0_bucket', 'pay_2_bucket', 'pay_3_bucket', 'pay_4_bucket', 'pay_5_bucket', 'pay_6_bucket', 'LIMIT_BAL_bucket'\n",
    "df.drop(columns=['pay_0_bucket', 'pay_2_bucket', 'pay_3_bucket', 'pay_4_bucket', 'pay_5_bucket', 'pay_6_bucket', 'LIMIT_BAL_bucket'], inplace=True)\n",
    "\n",
    "#print dimensions of the dataset\n",
    "print(\"Final dataset shape:\", df.shape)\n",
    "\n",
    "#print cols\n",
    "print(\"Columns in the final dataset:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65aff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf71239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. UTILIZATION FEATURES\n",
    "df['utilization'] = df[[f'Bill_amt{i}' for i in range(1, 7)]].sum(axis=1) / (6 * df['LIMIT_BAL'] + 1e-6)\n",
    "df['recent_utilization'] = df['Bill_amt1'] / (df['LIMIT_BAL'] + 1e-6)\n",
    "\n",
    "# 2. PAYMENT TO BILL RATIOS\n",
    "df['avg_pay_ratio'] = df[[f'pay_amt{i}' for i in range(1, 7)]].sum(axis=1) / (df[[f'Bill_amt{i}' for i in range(1, 7)]].sum(axis=1) + 1e-6)\n",
    "df['recent_payment_ratio'] = df['pay_amt1'] / (df['Bill_amt1'] + 1e-6)\n",
    "\n",
    "# 3. BILL AND PAYMENT STATS\n",
    "df['bill_mean'] = df[[f'Bill_amt{i}' for i in range(1, 7)]].mean(axis=1)\n",
    "df['bill_std'] = df[[f'Bill_amt{i}' for i in range(1, 7)]].std(axis=1)\n",
    "df['pay_mean'] = df[[f'pay_amt{i}' for i in range(1, 7)]].mean(axis=1)\n",
    "df['pay_std'] = df[[f'pay_amt{i}' for i in range(1, 7)]].std(axis=1)\n",
    "\n",
    "# 4. DELINQUENCY STREAKS & PATTERNS\n",
    "pay_cols = ['pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']\n",
    "df['overdue_count'] = (df[pay_cols] >= 1).sum(axis=1)\n",
    "df['on_time_count'] = (df[pay_cols] == -1).sum(axis=1)\n",
    "df['avg_delinquency'] = df[pay_cols].replace([-2, -1], 0).mean(axis=1)\n",
    "df['recent_delinquency'] = df['pay_0'].apply(lambda x: max(x, 0))\n",
    "\n",
    "# Max consecutive months of delay\n",
    "def max_consec(arr):\n",
    "    max_run = run = 0\n",
    "    for x in arr:\n",
    "        if x >= 1:\n",
    "            run += 1\n",
    "            max_run = max(max_run, run)\n",
    "        else:\n",
    "            run = 0\n",
    "    return max_run\n",
    "df['max_overdue_streak'] = df[pay_cols].apply(lambda row: max_consec(row.values), axis=1)\n",
    "\n",
    "# Months since last overdue\n",
    "def last_overdue(row):\n",
    "    for i, x in enumerate(row):\n",
    "        if x >= 1:\n",
    "            return i  # 0 = most recent\n",
    "    return len(row)\n",
    "df['months_since_overdue'] = df[pay_cols].apply(lambda r: last_overdue(r.values), axis=1)\n",
    "\n",
    "# 5. PAYMENT CONSISTENCY\n",
    "df['repayment_consistency'] = df[[f'pay_amt{i}' for i in range(1, 7)]].apply(lambda row: (row > 0).sum(), axis=1) / 6\n",
    "\n",
    "# 6. SHORTFALL & BEHAVIOR RATIOS\n",
    "df['shortfall_count'] = sum(df[f'pay_amt{i}'] < df[f'Bill_amt{i}'] for i in range(1, 7))\n",
    "df['rev_to_ontime'] = (df[pay_cols] == 0).sum(axis=1) / ((df[pay_cols] == -1).sum(axis=1) + 1e-6)\n",
    "df['rev_to_ontime'].fillna(0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b55c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot overall correlation matrix\n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, linewidths=0.5)\n",
    "plt.title('Correlation Matrix (Numeric Features)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06603fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'age', 'education', 'marriage', 'sex',\n",
    "    'utilization', 'recent_utilization', 'avg_pay_ratio', 'recent_payment_ratio',\n",
    "    'bill_mean', 'bill_std',  'pay_std','pay_mean',\n",
    "    'overdue_count', 'on_time_count', 'avg_delinquency', 'recent_delinquency',\n",
    "    'max_overdue_streak', 'months_since_overdue', 'repayment_consistency',\n",
    "    'shortfall_count', 'rev_to_ontime', \n",
    "    'LIMIT_BAL', \n",
    "    'AVG_Bill_amt',\t'PAY_TO_BILL_ratio'\n",
    "]\n",
    "\n",
    "X = df[selected_features]\n",
    "y = df['next_month_default']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Stratified Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ca39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import fbeta_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.combine import SMOTETomek\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Resample with SMOTETomek ---\n",
    "smk = SMOTETomek(random_state=42)\n",
    "X_train_res, y_train_res = smk.fit_resample(X_train, y_train)\n",
    "\n",
    "# Convert resampled data to DataFrame (optional: use original column names)\n",
    "X_train_res = pd.DataFrame(X_train_res, columns=X_train.columns if hasattr(X_train, 'columns') else None)\n",
    "X_test = pd.DataFrame(X_test, columns=X_test.columns if hasattr(X_test, 'columns') else None)\n",
    "\n",
    "# Convert all columns to numeric float32, filling any NaNs with 0\n",
    "X_train_res = X_train_res.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
    "\n",
    "# Make sure target variables are 1D numpy arrays\n",
    "if isinstance(y_train_res, pd.DataFrame):\n",
    "    y_train_res = y_train_res.iloc[:, 0]\n",
    "y_train_res = np.array(y_train_res).ravel()\n",
    "\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.iloc[:, 0]\n",
    "y_test = np.array(y_test).ravel()\n",
    "\n",
    "\n",
    "# --- Class Imbalance Weight for XGBoost ---\n",
    "pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# --- Model Definitions ---\n",
    "logreg = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_estimators=200, max_depth=10, random_state=42)\n",
    "xgb = XGBClassifier(scale_pos_weight=pos_weight, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': logreg,\n",
    "    'Random Forest': rf,\n",
    "    'XGBoost': xgb\n",
    "}\n",
    "\n",
    "# --- Evaluation Function ---\n",
    "def evaluate_model(name, model):\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Find best threshold for F2-score\n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    f2_scores = [fbeta_score(y_test, y_proba >= t, beta=2) for t in thresholds]\n",
    "    best_thresh = thresholds[np.argmax(f2_scores)]\n",
    "\n",
    "    y_pred = (y_proba >= best_thresh).astype(int)\n",
    "\n",
    "    print(f\"\\n{name} — Best Threshold for F2: {best_thresh:.2f}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "    print(\"F1-score:\", fbeta_score(y_test, y_pred, beta=1))\n",
    "    print(\"F2-score:\", fbeta_score(y_test, y_pred, beta=2))\n",
    "    print(\"AUC-ROC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-score': fbeta_score(y_test, y_pred, beta=1),\n",
    "        'F2-score': fbeta_score(y_test, y_pred, beta=2),\n",
    "        'AUC-ROC': roc_auc_score(y_test, y_proba)\n",
    "    }\n",
    "\n",
    "# --- Train and Evaluate Models ---\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    results.append(evaluate_model(name, model))\n",
    "\n",
    "# --- Display Results ---\n",
    "results_df = pd.DataFrame(results).set_index('Model')\n",
    "results_df = results_df.sort_values('F2-score', ascending=False)\n",
    "print(\"\\nFinal Model Comparison:\\n\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3115b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import fbeta_score\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # 1. Retrain RF on the full resampled data\n",
    "# best_rf = RandomForestClassifier(\n",
    "#     class_weight='balanced',\n",
    "#     n_estimators=200,\n",
    "#     max_depth=10,\n",
    "#     random_state=42\n",
    "# )\n",
    "# best_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# # 2. Predict on X_test\n",
    "# y_proba_test = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # 3. Evaluate across thresholds\n",
    "# thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "# records = []\n",
    "# for t in thresholds:\n",
    "#     y_pred_t = (y_proba_test >= t).astype(int)\n",
    "#     f2 = fbeta_score(y_test, y_pred_t, beta=2)\n",
    "#     positives = y_pred_t.sum()\n",
    "#     records.append({\n",
    "#         'Threshold': t,\n",
    "#         'F2‑Score': f2,\n",
    "#         'Predicted 1s': positives\n",
    "#     })\n",
    "\n",
    "# # 4. Build DataFrame & find best threshold\n",
    "# results_df = pd.DataFrame(records)\n",
    "# best_row = results_df.loc[results_df['F2‑Score'].idxmax()]\n",
    "\n",
    "# print(\"\\n🏆 Threshold with Highest F2:\")\n",
    "# print(best_row.to_frame().T.to_string(index=False))\n",
    "\n",
    "# print(\"\\n📊 Full threshold table (first 10 rows):\")\n",
    "# print(results_df.head(10).to_string(index=False))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "# Step 1: Retrain RF on full resampled data\n",
    "best_rf = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "best_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Step 2: Predict on X_test\n",
    "y_proba_test = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 3: Evaluate thresholds and capture results\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "records = []\n",
    "for t in thresholds:\n",
    "    preds = (y_proba_test >= t).astype(int)\n",
    "    f2 = fbeta_score(y_test, preds, beta=2, zero_division=0)\n",
    "    positives = preds.sum()\n",
    "    records.append((t, f2, positives))\n",
    "    # Debug print per iteration\n",
    "    print(f\"Threshold {t:.2f} — F2: {f2:.4f}, PredictedPositives: {positives}\")\n",
    "\n",
    "# Step 4: Build DataFrame\n",
    "results_df = pd.DataFrame(records, columns=['Threshold', 'F2-Score', 'Predicted_1s'])\n",
    "\n",
    "# Show only top and bottom, then full if small\n",
    "print(\"\\nTop 5 thresholds by F2 score:\")\n",
    "print(results_df.nlargest(5, 'F2-Score').to_string(index=False))\n",
    "\n",
    "print(\"\\nFull threshold table:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Step 5: Display best threshold summary\n",
    "best_row = results_df.loc[results_df['F2-Score'].idxmax()]\n",
    "print(\"\\n🏆 Best threshold for F2:\")\n",
    "print(best_row.to_frame().T.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ea670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Load validation dataset ---\n",
    "validate_df = pd.read_csv(\"validate_dataset_final.csv\")\n",
    "\n",
    "# --- Step 2: Preprocess validation dataset ---\n",
    "# Feature engineering to match training data\n",
    "\n",
    "# 1. UTILIZATION FEATURES\n",
    "validate_df['utilization'] = validate_df[[f'Bill_amt{i}' for i in range(1, 7)]].sum(axis=1) / (6 * validate_df['LIMIT_BAL'] + 1e-6)\n",
    "validate_df['recent_utilization'] = validate_df['Bill_amt1'] / (validate_df['LIMIT_BAL'] + 1e-6)\n",
    "\n",
    "# 2. PAYMENT TO BILL RATIOS\n",
    "validate_df['avg_pay_ratio'] = validate_df[[f'pay_amt{i}' for i in range(1, 7)]].sum(axis=1) / (validate_df[[f'Bill_amt{i}' for i in range(1, 7)]].sum(axis=1) + 1e-6)\n",
    "validate_df['recent_payment_ratio'] = validate_df['pay_amt1'] / (validate_df['Bill_amt1'] + 1e-6)\n",
    "\n",
    "# 3. BILL AND PAYMENT STATS\n",
    "validate_df['bill_mean'] = validate_df[[f'Bill_amt{i}' for i in range(1, 7)]].mean(axis=1)\n",
    "validate_df['bill_std'] = validate_df[[f'Bill_amt{i}' for i in range(1, 7)]].std(axis=1)\n",
    "validate_df['pay_mean'] = validate_df[[f'pay_amt{i}' for i in range(1, 7)]].mean(axis=1)\n",
    "validate_df['pay_std'] = validate_df[[f'pay_amt{i}' for i in range(1, 7)]].std(axis=1)\n",
    "\n",
    "# 4. DELINQUENCY STREAKS & PATTERNS\n",
    "pay_cols = ['pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']\n",
    "validate_df['overdue_count'] = (validate_df[pay_cols] >= 1).sum(axis=1)\n",
    "validate_df['avg_delinquency'] = validate_df[pay_cols].replace([-2, -1], 0).mean(axis=1)\n",
    "validate_df['on_time_count'] = (validate_df[pay_cols] == -1).sum(axis=1)\n",
    "validate_df['recent_delinquency'] = validate_df['pay_0'].apply(lambda x: max(x, 0))\n",
    "\n",
    "# Max consecutive months of delay\n",
    "def max_consec(arr):\n",
    "    max_run = run = 0\n",
    "    for x in arr:\n",
    "        if x >= 1:\n",
    "            run += 1\n",
    "            max_run = max(max_run, run)\n",
    "        else:\n",
    "            run = 0\n",
    "    return max_run\n",
    "validate_df['max_overdue_streak'] = validate_df[pay_cols].apply(lambda row: max_consec(row.values), axis=1)\n",
    "\n",
    "# Months since last overdue\n",
    "def last_overdue(row):\n",
    "    for i, x in enumerate(row):\n",
    "        if x >= 1:\n",
    "            return i  # 0 = most recent\n",
    "    return len(row)\n",
    "validate_df['months_since_overdue'] = validate_df[pay_cols].apply(lambda r: last_overdue(r.values), axis=1)\n",
    "\n",
    "# 5. PAYMENT CONSISTENCY\n",
    "validate_df['repayment_consistency'] = validate_df[[f'pay_amt{i}' for i in range(1, 7)]].apply(lambda row: (row > 0).sum(), axis=1) / 6\n",
    "\n",
    "# 6. SHORTFALL & BEHAVIOR RATIOS\n",
    "validate_df['shortfall_count'] = sum(validate_df[f'pay_amt{i}'] < validate_df[f'Bill_amt{i}'] for i in range(1, 7))\n",
    "validate_df['rev_to_ontime'] = (validate_df[pay_cols] == 0).sum(axis=1) / ((validate_df[pay_cols] == -1).sum(axis=1) + 1e-6)\n",
    "validate_df['rev_to_ontime'].fillna(0, inplace=True)\n",
    "\n",
    "# Now select columns in the same order as X_train_res\n",
    "validate_df = validate_df[X_train_res.columns]\n",
    "\n",
    "# Convert to float32 and handle any non-numeric entries\n",
    "validate_df = validate_df.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
    "\n",
    "# --- Step 3: Make predictions using the trained Random Forest model ---\n",
    "# Use threshold based on F2-score (e.g., 0.24 from your output)\n",
    "best_threshold = 0.24\n",
    "\n",
    "# Predict probabilities\n",
    "validate_probs = rf.predict_proba(validate_df)[:, 1]\n",
    "\n",
    "# Apply threshold\n",
    "validate_preds = (validate_probs >= best_threshold).astype(int)\n",
    "\n",
    "# --- Step 4: Save predictions ---\n",
    "output_df = pd.DataFrame({\n",
    "    'ID': validate_df.index,  # or any other ID column if present in original CSV\n",
    "    'Default_Prediction': validate_preds\n",
    "})\n",
    "\n",
    "output_df.to_csv(\"validation_predictions.csv\", index=False)\n",
    "\n",
    "print(\"✅ Predictions saved to validation_predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
